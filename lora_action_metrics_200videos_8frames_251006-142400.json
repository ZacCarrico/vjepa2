{
  "timestamp": "251006-142400",
  "approach": "lora",
  "num_videos_per_class": 200,
  "num_train_videos": 560,
  "num_val_videos": 120,
  "num_test_videos": 120,
  "frames_per_clip": 8,
  "num_epochs": 5,
  "batch_size": 1,
  "accumulation_steps": 4,
  "learning_rate": 0.0002,
  "weight_decay": 0.01,
  "num_workers": 0,
  "seed": 42,
  "model_name": "facebook/vjepa2-vitl-fpc16-256-ssv2",
  "lora_rank": 64,
  "lora_alpha": 128.0,
  "lora_dropout": 0.1,
  "epochs": [
    1,
    2,
    3,
    4,
    5
  ],
  "train_loss": [
    0.9541736547203202,
    0.7134777260195863,
    0.608923142711449,
    0.5451966537973411,
    0.5410372355059215
  ],
  "val_acc": [
    0.6083333333333333,
    0.7166666666666667,
    0.7083333333333334,
    0.775,
    0.7166666666666667
  ],
  "trainable_params": 1970180,
  "total_params": 377277828,
  "final_test_acc": 0.7666666666666667,
  "final_train_acc": 0.7767857142857143,
  "best_val_acc": 0.775,
  "best_epoch": 4,
  "inference_time_ms": 326.5845477581024,
  "per_class_metrics": {
    "sitting_down": {
      "precision": 0.75,
      "recall": 0.967741935483871,
      "f1": 0.8450704225352113
    },
    "standing_up": {
      "precision": 0.9090909090909091,
      "recall": 0.8333333333333334,
      "f1": 0.8695652173913043
    },
    "waving": {
      "precision": 0.7,
      "recall": 0.7241379310344828,
      "f1": 0.711864406779661
    },
    "other": {
      "precision": 0.6470588235294118,
      "recall": 0.4583333333333333,
      "f1": 0.5365853658536586
    }
  },
  "total_training_time": 2202.1063117980957
}